{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   listing_id       date available  price\n0      241032 2016-01-04         t   85.0\n1      241032 2016-01-05         t   85.0\n2      241032 2016-01-06         f    NaN\n3      241032 2016-01-07         f    NaN\n4      241032 2016-01-08         f    NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>listing_id</th>\n      <th>date</th>\n      <th>available</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>241032</td>\n      <td>2016-01-04</td>\n      <td>t</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>241032</td>\n      <td>2016-01-05</td>\n      <td>t</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>241032</td>\n      <td>2016-01-06</td>\n      <td>f</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>241032</td>\n      <td>2016-01-07</td>\n      <td>f</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>241032</td>\n      <td>2016-01-08</td>\n      <td>f</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy\n",
    "import seaborn\n",
    "\n",
    "# Read in the data and display the first 5 columns\n",
    "dataframe = pandas.read_csv('./calendar.csv')\n",
    "\n",
    "# Set the date column to be a pandas datetime column\n",
    "dataframe['date'] = pandas.to_datetime(dataframe['date'])\n",
    "\n",
    "# Set the price column to be a float\n",
    "dataframe['price'] = dataframe['price'].str.replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "dataframe.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To check the price delta between various times of year and between available and unavailable listings...clear up any NaN values for price"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(459028, 934542)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any null values in the available or date columns\n",
    "nullPrices = dataframe['price'].isnull().sum()\n",
    "\n",
    "notNullPrices = dataframe['price'].value_counts().sum()\n",
    "\n",
    "nullPrices, notNullPrices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 459,028 rows without a price, and 934,542 rows with a price. Check to see if all the rows without a price are rows that are not available"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "459028"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullPrices = dataframe.loc[dataframe['available'] == 'f']['price'].isnull().sum()\n",
    "\n",
    "nullPrices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The rows with unavailable listings do not list a price. What are some options for imputing the missing values? Get a list of available listings and prices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "      listing_id   price\n0           3335  120.00\n1           4291   82.00\n2           5682   52.50\n3           6606   95.00\n4           7369   85.00\n...          ...     ...\n3718    10331249   45.00\n3719    10332096   40.00\n3720    10334184  120.00\n3721    10339145  262.33\n3722    10340165   43.00\n\n[3723 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>listing_id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3335</td>\n      <td>120.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4291</td>\n      <td>82.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5682</td>\n      <td>52.50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6606</td>\n      <td>95.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7369</td>\n      <td>85.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3718</th>\n      <td>10331249</td>\n      <td>45.00</td>\n    </tr>\n    <tr>\n      <th>3719</th>\n      <td>10332096</td>\n      <td>40.00</td>\n    </tr>\n    <tr>\n      <th>3720</th>\n      <td>10334184</td>\n      <td>120.00</td>\n    </tr>\n    <tr>\n      <th>3721</th>\n      <td>10339145</td>\n      <td>262.33</td>\n    </tr>\n    <tr>\n      <th>3722</th>\n      <td>10340165</td>\n      <td>43.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>3723 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "availableListings = dataframe.loc[dataframe['available'] == 't'].copy()\n",
    "\n",
    "availableListings = availableListings[['listing_id', 'price']].groupby(['listing_id', 'price'], as_index=False)\n",
    "\n",
    "availableListings = availableListings.mean().groupby('listing_id')['price'].mean().round(2)\n",
    "\n",
    "availableListings = pandas.DataFrame(availableListings.reset_index())\n",
    "\n",
    "availableListings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An option would be to take these means values for available listings and fill all nan fields with their respective mean price based on the listing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def findAvailableListingMean(row):\n",
    "    if numpy.isnan(row['price']):\n",
    "        try:\n",
    "            mean_price = availableListings.loc[availableListings['listing_id'] == row['listing_id']]['price'].item()\n",
    "\n",
    "            return mean_price\n",
    "        except:\n",
    "            return row['price']\n",
    "    else:\n",
    "        return row['price']\n",
    "\n",
    "dataframe['price'] = dataframe.apply(\n",
    "    lambda row: findAvailableListingMean(row),\n",
    "    axis=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Putting it all together, graph a plot point with one set being the pricing per month for available listings, and the other unavailable listings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['month', 'price'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     23\u001B[0m unavailable_listings[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124munavailable\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     25\u001B[0m plot_data \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mconcat([available_listings, unavailable_listings])\n\u001B[1;32m---> 27\u001B[0m plot_data \u001B[38;5;241m=\u001B[39m \u001B[43mplot_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmonth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdataset\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprice\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     29\u001B[0m plot_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m plot_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmap({\u001B[38;5;241m1\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJanuary\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m2\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFebruary\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m3\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMarch\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m4\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mApril\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m5\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMay\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m6\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJune\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m7\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJuly\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m8\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAugust\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m9\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSeptember\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m10\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOctober\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m11\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNovember\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m12\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDecember\u001B[39m\u001B[38;5;124m'\u001B[39m})\n\u001B[0;32m     31\u001B[0m pyplot\u001B[38;5;241m.\u001B[39msubplots(figsize \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m15\u001B[39m,\u001B[38;5;241m10\u001B[39m))\n",
      "File \u001B[1;32mc:\\projects\\udacity\\becomeadatascientist\\venv\\lib\\site-packages\\pandas\\core\\series.py:985\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    982\u001B[0m     key \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(key, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m)\n\u001B[0;32m    983\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_values(key)\n\u001B[1;32m--> 985\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_with\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\projects\\udacity\\becomeadatascientist\\venv\\lib\\site-packages\\pandas\\core\\series.py:1025\u001B[0m, in \u001B[0;36mSeries._get_with\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1022\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[key]\n\u001B[0;32m   1024\u001B[0m \u001B[38;5;66;03m# handle the dup indexing case GH#4246\u001B[39;00m\n\u001B[1;32m-> 1025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32mc:\\projects\\udacity\\becomeadatascientist\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    964\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    966\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m--> 967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\projects\\udacity\\becomeadatascientist\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1188\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1193\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32mc:\\projects\\udacity\\becomeadatascientist\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1132\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1129\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[1;32m-> 1132\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1133\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(\n\u001B[0;32m   1134\u001B[0m     {axis: [keyarr, indexer]}, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m )\n",
      "File \u001B[1;32mc:\\projects\\udacity\\becomeadatascientist\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1324\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1325\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[1;32m-> 1327\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[1;32mc:\\projects\\udacity\\becomeadatascientist\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   5779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   5780\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 5782\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5784\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   5785\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   5786\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32mc:\\projects\\udacity\\becomeadatascientist\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   5842\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   5844\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 5845\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['month', 'price'] not in index\""
     ]
    }
   ],
   "source": [
    "# Plot a bar graph detailing average price per month\n",
    "def slice_by_availability(_dataframe, availability):\n",
    "    listings = _dataframe.loc[_dataframe['available'] == availability].copy()\n",
    "    \n",
    "    listings['month'] = pandas.to_datetime(listings['date']).dt.month\n",
    "    listings['year'] = pandas.to_datetime(listings['date']).dt.year\n",
    "\n",
    "    listings = listings.loc[listings['year'] == 2016].copy()\n",
    "    \n",
    "    listings_per_month = pandas.Series([12])\n",
    "\n",
    "    for i in range(1, 13):\n",
    "        listings_per_month[i] = len(listings.loc[listings['month'] == i]['listing_id'].unique())\n",
    "\n",
    "    listings_per_month = listings_per_month.drop(0)\n",
    "    \n",
    "    return listings_per_month\n",
    "\n",
    "available_listings = slice_by_availability(dataframe, 't')\n",
    "unavailable_listings = slice_by_availability(dataframe, 'f')\n",
    "\n",
    "plot_data = pandas.concat([available_listings.assign(dataset='available'), unavailable_listings.assign(dataset='unavailable')])\n",
    "\n",
    "plot_data = plot_data[['month', 'dataset', 'price']]\n",
    "\n",
    "plot_data['month'] = plot_data['month'].map({1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'})\n",
    "\n",
    "pyplot.subplots(figsize = (15,10))\n",
    "seaborn.pointplot(x = 'month', y = 'price', hue='dataset', data=plot_data)\n",
    "pyplot.ylabel('Price')\n",
    "pyplot.xlabel('Months')\n",
    "pyplot.title('2016 average price of available and unavailable listings per month')\n",
    "\n",
    "pyplot.savefig('available_listings_vs_unavailable_listings_price_2016.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "           month      dataset  price\n0        January    available   85.0\n1        January    available   85.0\n9        January    available   85.0\n10       January    available   85.0\n14       January    available   85.0\n...          ...          ...    ...\n1393207  January  unavailable   87.0\n1393208  January  unavailable   87.0\n1393211  January  unavailable   87.0\n1393212  January  unavailable   87.0\n1393213  January  unavailable   87.0\n\n[1857688 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>month</th>\n      <th>dataset</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>January</td>\n      <td>available</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>January</td>\n      <td>available</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>January</td>\n      <td>available</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>January</td>\n      <td>available</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>January</td>\n      <td>available</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1393207</th>\n      <td>January</td>\n      <td>unavailable</td>\n      <td>87.0</td>\n    </tr>\n    <tr>\n      <th>1393208</th>\n      <td>January</td>\n      <td>unavailable</td>\n      <td>87.0</td>\n    </tr>\n    <tr>\n      <th>1393211</th>\n      <td>January</td>\n      <td>unavailable</td>\n      <td>87.0</td>\n    </tr>\n    <tr>\n      <th>1393212</th>\n      <td>January</td>\n      <td>unavailable</td>\n      <td>87.0</td>\n    </tr>\n    <tr>\n      <th>1393213</th>\n      <td>January</td>\n      <td>unavailable</td>\n      <td>87.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1857688 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By imputing the average price for an available listing onto the NaN values for unavailable listings it's clear there's at least some correlation between price and availability. However, the imputation is limited by a number of factors. For example, a price might be higher due to higher demand which would be missing from the mean."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}